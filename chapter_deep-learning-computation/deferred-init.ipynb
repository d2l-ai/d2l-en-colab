{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mxnet-cu101==1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Deferred Initialization\n",
    ":label:`sec_deferred_init`\n",
    "\n",
    "Até agora, pode parecer que escapamos\n",
    "por ser descuidados na configuração de nossas redes.\n",
    "Especificamente, fizemos as seguintes coisas não intuitivas,\n",
    "que podem não parecer que deveriam funcionar:\n",
    "\n",
    "* Definimos as arquiteturas de rede\n",
    "   sem especificar a dimensionalidade de entrada.\n",
    "* Adicionamos camadas sem especificar\n",
    "   a dimensão de saída da camada anterior.\n",
    "* Nós até \"inicializamos\" esses parâmetros\n",
    "   antes de fornecer informações suficientes para determinar\n",
    "   quantos parâmetros nossos modelos devem conter.\n",
    "\n",
    "Você pode se surpreender com o fato de nosso código ser executado.\n",
    "Afinal, não há como o *framework* de *Deep Learning*\n",
    "poderia dizer qual seria a dimensionalidade de entrada de uma rede.\n",
    "O truque aqui é que o *framework* adia a inicialização,\n",
    "esperando até a primeira vez que passamos os dados pelo modelo,\n",
    "para inferir os tamanhos de cada camada na hora.\n",
    "\n",
    "Mais tarde, ao trabalhar com redes neurais convolucionais,\n",
    "esta técnica se tornará ainda mais conveniente\n",
    "desde a dimensionalidade de entrada\n",
    "(ou seja, a resolução de uma imagem)\n",
    "afetará a dimensionalidade\n",
    "de cada camada subsequente.\n",
    "Consequentemente, a capacidade de definir parâmetros\n",
    "sem a necessidade de saber,\n",
    "no momento de escrever o código,\n",
    "qual é a dimensionalidade\n",
    "pode simplificar muito a tarefa de especificar\n",
    "e subsequentemente modificando nossos modelos.\n",
    "A seguir, vamos nos aprofundar na mecânica da inicialização.\n",
    "\n",
    "\n",
    "## Instanciando a Rede\n",
    "\n",
    "Para começar, vamos instanciar um MLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    net.add(nn.Dense(10))\n",
    "    return net\n",
    "\n",
    "net = get_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "Neste ponto, a rede não pode saber\n",
    "as dimensões dos pesos da camada de entrada\n",
    "porque a dimensão de entrada permanece desconhecida.\n",
    "Consequentemente, a estrutura ainda não inicializou nenhum parâmetro.\n",
    "Confirmamos tentando acessar os parâmetros abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Block.collect_params of Sequential(\n",
      "  (0): Dense(-1 -> 256, Activation(relu))\n",
      "  (1): Dense(-1 -> 10, linear)\n",
      ")>\n",
      "sequential0_ (\n",
      "  Parameter dense0_weight (shape=(256, -1), dtype=float32)\n",
      "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
      "  Parameter dense1_weight (shape=(10, -1), dtype=float32)\n",
      "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net.collect_params)\n",
    "print(net.collect_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "Observe que, embora os objetos de parâmetro existam,\n",
    "a dimensão de entrada para cada camada é listada como -1.\n",
    "MXNet usa o valor especial -1 para indicar\n",
    "que a dimensão do parâmetro permanece desconhecida.\n",
    "Neste ponto, tenta acessar `net [0].weight.data()`\n",
    "desencadearia um erro de tempo de execução informando que a rede\n",
    "deve ser inicializado antes que os parâmetros possam ser acessados.\n",
    "Agora vamos ver o que acontece quando tentamos inicializar\n",
    "parâmetros por meio da função `initialize`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, -1), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, -1), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "Como podemos ver, nada mudou.\n",
    "Quando as dimensões de entrada são desconhecidas,\n",
    "chamadas para inicializar não inicializam corretamente os parâmetros.\n",
    "Em vez disso, esta chamada se registra no MXNet que desejamos\n",
    "(e opcionalmente, de acordo com qual distribuição)\n",
    "para inicializar os parâmetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "Em seguida, vamos passar os dados pela rede\n",
    "para fazer o *framework* finalmente inicializar os parâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, 256), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.uniform(size=(2, 20))\n",
    "net(X)\n",
    "\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "Assim que sabemos a dimensionalidade da entrada,\n",
    "20,\n",
    "a estrutura pode identificar a forma da matriz de peso da primeira camada conectando o valor de 20.\n",
    "Tendo reconhecido a forma da primeira camada, a estrutura prossegue\n",
    "para a segunda camada,\n",
    "e assim por diante através do grafo computacional\n",
    "até que todas as formas sejam conhecidas.\n",
    "Observe que, neste caso,\n",
    "apenas a primeira camada requer inicialização adiada,\n",
    "mas a estrutura inicializa sequencialmente.\n",
    "Uma vez que todas as formas dos parâmetros são conhecidas,\n",
    "a estrutura pode finalmente inicializar os parâmetros.\n",
    "\n",
    "## Sumário\n",
    "\n",
    "* A inicialização adiada pode ser conveniente, permitindo ao *framework* inferir formas de parâmetros automaticamente, facilitando a modificação de arquiteturas e eliminando uma fonte comum de erros.\n",
    "* Podemos passar dados através do modelo para fazer o *framework* finalmente inicializar os parâmetros.\n",
    "\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "1. O que acontece se você especificar as dimensões de entrada para a primeira camada, mas não para as camadas subsequentes? Você consegue inicialização imediata?\n",
    "1. O que acontece se você especificar dimensões incompatíveis?\n",
    "1. O que você precisa fazer se tiver dados de dimensionalidade variável? Dica: observe a vinculação de parâmetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "[Discussão](https://discuss.d2l.ai/t/280)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbNzExNDA4MzAxLC0zODc0Mjc4NTEsNjQ1Nz\n",
    "g1NDQyLDExMzU1ODY3NzRdfQ==\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
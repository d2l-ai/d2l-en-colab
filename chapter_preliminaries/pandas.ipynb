{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b39b35",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e760a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mxnet-cu101==1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d10a3",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Data Preprocessing\n",
    ":label:`sec_pandas`\n",
    "\n",
    "So far we have introduced a variety of techniques for manipulating data that are already stored in tensors.\n",
    "To apply deep learning to solving real-world problems,\n",
    "we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format.\n",
    "Among popular data analytic tools in Python, the `pandas` package is commonly used.\n",
    "Like many other extension packages in the vast ecosystem of Python,\n",
    "`pandas` can work together with tensors.\n",
    "So, we will briefly walk through steps for preprocessing raw data with `pandas`\n",
    "and converting them into the tensor format.\n",
    "We will cover more data preprocessing techniques in later chapters.\n",
    "\n",
    "## Reading the Dataset\n",
    "\n",
    "As an example,\n",
    "we begin by (**creating an artificial dataset that is stored in a\n",
    "csv (comma-separated values) file**)\n",
    "`../data/house_tiny.csv`. Data stored in other\n",
    "formats may be processed in similar ways.\n",
    "\n",
    "Below we write the dataset row by row into a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66713103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T01:24:21.382390Z",
     "iopub.status.busy": "2022-07-10T01:24:21.381742Z",
     "iopub.status.idle": "2022-07-10T01:24:21.391236Z",
     "shell.execute_reply": "2022-07-10T01:24:21.390385Z"
    },
    "origin_pos": 1,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
    "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff38e4",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "To [**load the raw dataset from the created csv file**],\n",
    "we import the `pandas` package and invoke the `read_csv` function.\n",
    "This dataset has four rows and three columns, where each row describes the number of rooms (\"NumRooms\"), the alley type (\"Alley\"), and the price (\"Price\") of a house.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e1bb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T01:24:21.609013Z",
     "iopub.status.busy": "2022-07-10T01:24:21.608686Z",
     "iopub.status.idle": "2022-07-10T01:24:22.062567Z",
     "shell.execute_reply": "2022-07-10T01:24:22.061726Z"
    },
    "origin_pos": 3,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "# If pandas is not installed, just uncomment the following line:\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96785acd",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Note that \"NaN\" entries are missing values.\n",
    "To handle missing data, typical methods include *imputation* and *deletion*,\n",
    "where imputation replaces missing values with substituted ones,\n",
    "while deletion ignores missing values. Here we will consider imputation.\n",
    "\n",
    "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
    "where the former takes the first two columns while the latter only keeps the last column.\n",
    "For numerical values in `inputs` that are missing,\n",
    "we [**replace the \"NaN\" entries with the mean value of the same column.**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff70f3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T01:24:22.066233Z",
     "iopub.status.busy": "2022-07-10T01:24:22.065771Z",
     "iopub.status.idle": "2022-07-10T01:24:22.074287Z",
     "shell.execute_reply": "2022-07-10T01:24:22.073502Z"
    },
    "origin_pos": 5,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f48c3",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "[**For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.**]\n",
    "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
    "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n",
    "A row whose alley type is \"Pave\" will set values of \"Alley_Pave\" and \"Alley_nan\" to 1 and 0.\n",
    "A row with a missing alley type will set their values to 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702a12dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T01:24:22.077895Z",
     "iopub.status.busy": "2022-07-10T01:24:22.077276Z",
     "iopub.status.idle": "2022-07-10T01:24:22.087925Z",
     "shell.execute_reply": "2022-07-10T01:24:22.087104Z"
    },
    "origin_pos": 7,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca62ca",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## Conversion to the Tensor Format\n",
    "\n",
    "Now that [**all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.**]\n",
    "Once data are in this format, they can be further manipulated with those tensor functionalities that we have introduced in :numref:`sec_ndarray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d174d0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T01:24:22.091351Z",
     "iopub.status.busy": "2022-07-10T01:24:22.090918Z",
     "iopub.status.idle": "2022-07-10T01:24:23.263594Z",
     "shell.execute_reply": "2022-07-10T01:24:23.262774Z"
    },
    "origin_pos": 9,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3., 1., 0.],\n",
       "        [2., 0., 1.],\n",
       "        [4., 0., 1.],\n",
       "        [3., 0., 1.]], dtype=float64),\n",
       " array([127500, 106000, 178100, 140000], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import np\n",
    "\n",
    "X, y = np.array(inputs.values), np.array(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbf82d",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
    "* Imputation and deletion can be used to handle missing data.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Create a raw dataset with more rows and columns.\n",
    "\n",
    "1. Delete the column with the most missing values.\n",
    "2. Convert the preprocessed dataset to the tensor format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3e366",
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/28)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}